version: '3.7'

services:
  kafka:
    image: confluentinc/cp-kafka:5.2.2
    restart: unless-stopped
    hostname: kafka
    expose:
      - "9092"
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://localhost:9092"
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_MS: 3600000
      KAFKA_HEAP_OPTS: "-Xms500m -Xmx1500m -XX:MetaspaceSize=96m"
    volumes:
      - kafka_data:/var/lib/kafka/data
    depends_on:
      - zookeeper
    command: |
      bash -c '/etc/confluent/docker/run & \
      cub kafka-ready -z zookeeper 1 120 && \
      kafka-topics --create --topic messages --partitions 8 --replication-factor 1 --if-not-exists --zookeeper zookeeper --config retention.ms=172800000 ; \
      kafka-topics --alter --topic messages --partitions 8 --zookeeper zookeeper ; \
      kafka-configs --zookeeper zookeeper --entity-type topics --entity-name messages --alter --add-config retention.ms=172800000 ; \
      sleep infinity'

  zookeeper:
    image: confluentinc/cp-zookeeper:5.2.2
    restart: unless-stopped
    hostname: zookeeper
    ports:
      - "127.0.0.1:2181:2181"
    environment:
        ZOOKEEPER_SERVER_ID: 1
        ZOOKEEPER_CLIENT_PORT: 2181
    volumes:
      - zookeeper_data:/data
      - zookeeper_datalog:/datalog

volumes:
    zookeeper_data:
    zookeeper_datalog:
    kafka_data:

